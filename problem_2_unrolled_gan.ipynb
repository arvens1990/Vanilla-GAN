{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "problem_2_unrolled_gan.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python382jvsc74a57bd0a94883f8812057f41bf7c0f7649a41127778eaf25b6b91e0966940eb42cb8f65",
      "display_name": "Python 3.8.2 64-bit ('HW3': virtualenvwrapper)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.2"
    },
    "accelerator": "GPU",
    "metadata": {
      "interpreter": {
        "hash": "a94883f8812057f41bf7c0f7649a41127778eaf25b6b91e0966940eb42cb8f65"
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1t3QWTo82IWJ",
        "outputId": "51e43caa-f730-4b9b-eabd-1c56bf5fe5e2"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "mOn_JyJ7CVmi",
        "outputId": "3a2922c7-ee19-4e4b-d9d7-35770f79ec1e"
      },
      "source": [
        "# # clear shared RAM (Colab shares RAM and GPU with other user sessions, this guarantees all resources allocated to this session)\n",
        "# # memory footprint support libraries/code\n",
        "# !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "# !pip install gputil --quiet\n",
        "# !pip install psutil --quiet\n",
        "# !pip install humanize --quiet\n",
        "# import psutil\n",
        "# import humanize\n",
        "# import os\n",
        "# import GPUtil as GPU\n",
        "# GPUs = GPU.getGPUs()\n",
        "# # only one GPU on Colab and isn't guaranteed\n",
        "# gpu = GPUs[0]\n",
        "# proc = psutil.Process(os.getpid())\n",
        "# print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" | Proc size: \" + humanize.naturalsize(proc.memory_info().rss))\n",
        "# print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxMVkEcI2k4u"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision as tv\n",
        "import re\n",
        "import time\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.nn import Module, GRU, Embedding, Linear, Sigmoid, CrossEntropyLoss, ReLU, Tanh, Sequential\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "import torch.optim as optim\n",
        "from torchvision.utils import make_grid, save_image\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import imageio\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "from torchvision.utils import make_grid, save_image\n",
        "from torch.utils.data import DataLoader\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import copy\n",
        "matplotlib.style.use('ggplot')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGIf8C6GB7-5"
      },
      "source": [
        "# learning parameters\n",
        "batch_size = 512\n",
        "epochs = 200\n",
        "sample_size = 64 # fixed sample size\n",
        "nz = 128 # latent vector size\n",
        "k = 1 # number of steps to apply to the discriminator\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ldDzsOLBPMJ"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,),(0.5,)),\n",
        "])\n",
        "to_pil_image = transforms.ToPILImage()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmNXt6n12wRu"
      },
      "source": [
        "fmnist = datasets.FashionMNIST(root='./', train=True, download=True, transform=transform)\n",
        "data_loader = DataLoader(fmnist, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peaMJAPx4ss5"
      },
      "source": [
        "class Generator(Module):\n",
        "    def __init__(self, nz):\n",
        "        super(Generator, self).__init__()\n",
        "        self.nz = nz\n",
        "        self.main = Sequential(\n",
        "            Linear(self.nz, 256),\n",
        "            ReLU(),\n",
        "\n",
        "            Linear(256, 512),\n",
        "            ReLU(),\n",
        "\n",
        "            Linear(512, 784),\n",
        "            Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.main(x).view(-1, 1, 28, 28)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oJcazUH8iDS"
      },
      "source": [
        "class Discriminator(Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.n_input = 784\n",
        "        self.main = Sequential(\n",
        "            Linear(self.n_input, 1024),\n",
        "            ReLU(),\n",
        "            Linear(1024, 512),\n",
        "            ReLU(),\n",
        "            Linear(512, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        return self.main(x)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7adj8WbJ9qpH"
      },
      "source": [
        "Initialize the Neural Networks and Define the Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p51ZeaQa9Vge",
        "outputId": "8e23ab2d-5361-48f4-b774-3878420f416c"
      },
      "source": [
        "\n",
        "\n",
        "generator = Generator(nz).to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "# unrolled_discriminator = Discriminator().to(device)\n",
        "print('##### GENERATOR #####')\n",
        "print(generator)\n",
        "print('######################')\n",
        "print('\\n##### DISCRIMINATOR #####')\n",
        "print(discriminator)\n",
        "print('######################')\n",
        "# print('\\n##### UNROLLED DISCRIMINATOR #####')\n",
        "# print(unrolled_discriminator)\n",
        "# print('######################')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##### GENERATOR #####\nGenerator(\n  (main): Sequential(\n    (0): Linear(in_features=128, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=512, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=512, out_features=784, bias=True)\n    (5): Tanh()\n  )\n)\n######################\n\n##### DISCRIMINATOR #####\nDiscriminator(\n  (main): Sequential(\n    (0): Linear(in_features=784, out_features=1024, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=1024, out_features=512, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=512, out_features=1, bias=True)\n    (5): Sigmoid()\n  )\n)\n######################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKlcQe_n-bHR"
      },
      "source": [
        "# optimizers\n",
        "\n",
        "optim_g = optim.Adam(generator.parameters(), lr=0.0002)\n",
        "optim_d = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
        "optim_ud = optim.Adam(discriminator.parameters(), lr=0.0002)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPNn0bai-r8-"
      },
      "source": [
        "# loss function\n",
        "criterion = nn.BCELoss()\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQJ7sr__-yEb"
      },
      "source": [
        "losses_g = [] # to store generator loss after each epoch\n",
        "losses_d = [] # to store discriminator loss after each epoch\n",
        "lossed_ud = []\n",
        "images = [] # to store images generatd by the generator"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5L3H3nt_Pny"
      },
      "source": [
        "# to create real labels (1s)\n",
        "def label_real(size):\n",
        "    data = torch.ones(size, 1)\n",
        "    return data.to(device)\n",
        "# to create fake labels (0s)\n",
        "def label_fake(size):\n",
        "    data = torch.zeros(size, 1)\n",
        "    return data.to(device)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0BoEe0__VJf"
      },
      "source": [
        "def create_noise(sample_size, nz):\n",
        "    return torch.randn(sample_size, nz).to(device)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xu4X0hef_ZV-"
      },
      "source": [
        "# to save the images generated by the generator\n",
        "def save_generator_image(image, path):\n",
        "    save_image(image, path)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2Qqdkv4_qXO"
      },
      "source": [
        "# function to train the discriminator network\n",
        "def train_discriminator(optimizer, data_real, data_fake, discriminator):\n",
        "    b_size = data_real.size(0)\n",
        "    real_label = label_real(b_size)\n",
        "    fake_label = label_fake(b_size)\n",
        "    optimizer.zero_grad()\n",
        "    output_real = discriminator(data_real)\n",
        "    loss_real = criterion(output_real, real_label)\n",
        "    output_fake = discriminator(data_fake)\n",
        "    loss_fake = criterion(output_fake, fake_label)\n",
        "    loss_real.backward()\n",
        "    loss_fake.backward()\n",
        "    optimizer.step()\n",
        "    return loss_real + loss_fake"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANvhtzh1_3eu"
      },
      "source": [
        "# function to train the generator network\n",
        "def train_generator(optimizer, data_fake, discriminator):\n",
        "    b_size = data_fake.size(0)\n",
        "    real_label = label_real(b_size)\n",
        "    optimizer.zero_grad()\n",
        "    output = discriminator(data_fake)\n",
        "    loss = criterion(output, real_label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tT0w5o2-_5k3",
        "outputId": "d8c6bc76-69a9-492d-e322-6b05345e2a9d"
      },
      "source": [
        "# create the noise vector\n",
        "noise = create_noise(sample_size, nz)\n",
        "generator.train()\n",
        "discriminator.train()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (main): Sequential(\n",
              "    (0): Linear(in_features=784, out_features=1024, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=512, out_features=1, bias=True)\n",
              "    (5): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kc2K7_CUAULN",
        "outputId": "f0559880-398d-49fb-8768-aa11b20fdf89"
      },
      "source": [
        "# path = \"/content/drive/MyDrive/Deep_Learning/HW3/outputs_unrolled_gan/\"\n",
        "path = \"./models/unrolled/\"\n",
        "epochs = 200\n",
        "# k = 10\n",
        "\n",
        "losses_g = [] # to store generator loss after each epoch\n",
        "losses_d = [] # to store discriminator loss after each epoch\n",
        "losses_ud = []\n",
        "images = [] # to store images generatd by the generator\n",
        "length = 0.\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "    # length = 0.\n",
        "    loss_g = 0.0\n",
        "    loss_d = 0.0\n",
        "    loss_ud = 0.\n",
        "    for bi, data in enumerate(data_loader):\n",
        "        image, _ = data\n",
        "        image = image.to(device)\n",
        "        b_size = len(image)\n",
        "        # run the discriminator for k number of steps\n",
        "        for step in range(k):\n",
        "            # print(create_noise(b_size, nz).shape)\n",
        "            data_fake = generator(create_noise(b_size, nz)).detach()\n",
        "            data_real = image\n",
        "            # train the discriminator network\n",
        "            loss_d += train_discriminator(optim_d, data_real, data_fake, discriminator)\n",
        "\n",
        "            # unroll\n",
        "            unrolled_discriminator = copy.deepcopy(discriminator)\n",
        "            # print(unrolled_discriminator)\n",
        "            loss_ud += train_discriminator(optim_ud, data_real, data_fake, unrolled_discriminator)\n",
        "            \n",
        "\n",
        "        data_fake = generator(create_noise(b_size, nz))\n",
        "        # train the generator network\n",
        "        loss_g += train_generator(optim_g, data_fake, unrolled_discriminator)\n",
        "        del unrolled_discriminator\n",
        "    # create the final fake image for the epoch\n",
        "    if epoch%20==0:\n",
        "        generated_img = generator(noise).cpu().detach()\n",
        "        # make the images as grid\n",
        "        generated_img = make_grid(generated_img)\n",
        "        # save the generated torch tensor models to disk\n",
        "        save_generator_image(generated_img, path + f\"gen_img{epoch}.png\")\n",
        "    images.append(generated_img)\n",
        "    epoch_loss_g = loss_g / bi # total generator loss for the epoch\n",
        "    epoch_loss_d = loss_d / bi # total discriminator loss for the epoch\n",
        "    epoch_loss_ud = loss_ud / bi\n",
        "    losses_g.append(epoch_loss_g)\n",
        "    losses_d.append(epoch_loss_d)\n",
        "    losses_ud.append(epoch_loss_ud)\n",
        "    end = time.time() - start\n",
        "    length += end\n",
        "    mean_so_far = length / (epoch+1)\n",
        "    time_left = (mean_so_far * (epochs - epoch - 1))/60\n",
        "    \n",
        "    print(f\"Epoch {epoch} of {epochs}:\\t\\t{end:.2f} seconds;\\ttotal: {length:.2f};\\tminutes left: {time_left:.2f}\")\n",
        "    print(f\"Generator loss: {epoch_loss_g:.8f}, Discriminator loss: {epoch_loss_d:.5f}, Unrolled Discriminator loss: {epoch_loss_ud:.5f}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 of 200:\t\t38.10 seconds;\ttotal: 38.10;\tminutes left: 126.37\n",
            "Generator loss: 2.20679545, Discriminator loss: 0.40582, Unrolled Discriminator loss: 0.30710\n",
            "Epoch 1 of 200:\t\t38.35 seconds;\ttotal: 76.45;\tminutes left: 126.14\n",
            "Generator loss: 3.61607265, Discriminator loss: 0.10173, Unrolled Discriminator loss: 0.06430\n",
            "Epoch 2 of 200:\t\t39.32 seconds;\ttotal: 115.77;\tminutes left: 126.70\n",
            "Generator loss: 7.87997055, Discriminator loss: 0.01901, Unrolled Discriminator loss: 0.00890\n",
            "Epoch 3 of 200:\t\t37.41 seconds;\ttotal: 153.18;\tminutes left: 125.09\n",
            "Generator loss: 7.53028870, Discriminator loss: 0.01509, Unrolled Discriminator loss: 0.00774\n",
            "Epoch 4 of 200:\t\t38.14 seconds;\ttotal: 191.32;\tminutes left: 124.36\n",
            "Generator loss: 5.48966694, Discriminator loss: 0.01964, Unrolled Discriminator loss: 0.01238\n",
            "Epoch 5 of 200:\t\t36.45 seconds;\ttotal: 227.77;\tminutes left: 122.74\n",
            "Generator loss: 6.92530012, Discriminator loss: 0.01583, Unrolled Discriminator loss: 0.00865\n",
            "Epoch 6 of 200:\t\t37.21 seconds;\ttotal: 264.99;\tminutes left: 121.77\n",
            "Generator loss: 7.42756176, Discriminator loss: 0.01487, Unrolled Discriminator loss: 0.00824\n",
            "Epoch 7 of 200:\t\t38.44 seconds;\ttotal: 303.43;\tminutes left: 121.37\n",
            "Generator loss: 8.16188526, Discriminator loss: 0.01405, Unrolled Discriminator loss: 0.00756\n",
            "Epoch 8 of 200:\t\t38.91 seconds;\ttotal: 342.34;\tminutes left: 121.09\n",
            "Generator loss: 8.70465374, Discriminator loss: 0.01440, Unrolled Discriminator loss: 0.00741\n",
            "Epoch 9 of 200:\t\t38.35 seconds;\ttotal: 380.68;\tminutes left: 120.55\n",
            "Generator loss: 10.28251743, Discriminator loss: 0.01841, Unrolled Discriminator loss: 0.00984\n",
            "Epoch 10 of 200:\t\t38.48 seconds;\ttotal: 419.16;\tminutes left: 120.03\n",
            "Generator loss: 11.22005272, Discriminator loss: 0.05026, Unrolled Discriminator loss: 0.04839\n",
            "Epoch 11 of 200:\t\t39.00 seconds;\ttotal: 458.17;\tminutes left: 119.63\n",
            "Generator loss: 9.70535660, Discriminator loss: 0.16754, Unrolled Discriminator loss: 0.10989\n",
            "Epoch 12 of 200:\t\t38.26 seconds;\ttotal: 496.43;\tminutes left: 119.01\n",
            "Generator loss: 8.93791485, Discriminator loss: 0.20654, Unrolled Discriminator loss: 0.17713\n",
            "Epoch 13 of 200:\t\t37.93 seconds;\ttotal: 534.35;\tminutes left: 118.32\n",
            "Generator loss: 5.83862114, Discriminator loss: 0.07878, Unrolled Discriminator loss: 0.05952\n",
            "Epoch 14 of 200:\t\t38.36 seconds;\ttotal: 572.71;\tminutes left: 117.72\n",
            "Generator loss: 6.67460299, Discriminator loss: 0.06012, Unrolled Discriminator loss: 0.04868\n",
            "Epoch 15 of 200:\t\t40.20 seconds;\ttotal: 612.91;\tminutes left: 117.47\n",
            "Generator loss: 6.85612965, Discriminator loss: 0.23815, Unrolled Discriminator loss: 0.21545\n",
            "Epoch 16 of 200:\t\t42.19 seconds;\ttotal: 655.10;\tminutes left: 117.53\n",
            "Generator loss: 5.95256662, Discriminator loss: 0.05733, Unrolled Discriminator loss: 0.04461\n",
            "Epoch 17 of 200:\t\t40.83 seconds;\ttotal: 695.93;\tminutes left: 117.28\n",
            "Generator loss: 7.07026482, Discriminator loss: 0.11052, Unrolled Discriminator loss: 0.08413\n",
            "Epoch 18 of 200:\t\t40.11 seconds;\ttotal: 736.03;\tminutes left: 116.86\n",
            "Generator loss: 7.08071709, Discriminator loss: 0.05803, Unrolled Discriminator loss: 0.04161\n",
            "Epoch 19 of 200:\t\t40.76 seconds;\ttotal: 776.79;\tminutes left: 116.52\n",
            "Generator loss: 7.85883665, Discriminator loss: 0.07085, Unrolled Discriminator loss: 0.05297\n",
            "Epoch 20 of 200:\t\t41.42 seconds;\ttotal: 818.21;\tminutes left: 116.24\n",
            "Generator loss: 7.96683788, Discriminator loss: 0.06597, Unrolled Discriminator loss: 0.04777\n",
            "Epoch 21 of 200:\t\t40.11 seconds;\ttotal: 858.32;\tminutes left: 115.74\n",
            "Generator loss: 8.67352390, Discriminator loss: 0.06777, Unrolled Discriminator loss: 0.04490\n",
            "Epoch 22 of 200:\t\t40.14 seconds;\ttotal: 898.46;\tminutes left: 115.24\n",
            "Generator loss: 10.60926819, Discriminator loss: 0.08386, Unrolled Discriminator loss: 0.05606\n",
            "Epoch 23 of 200:\t\t40.57 seconds;\ttotal: 939.03;\tminutes left: 114.77\n",
            "Generator loss: 8.60357475, Discriminator loss: 0.08037, Unrolled Discriminator loss: 0.05999\n",
            "Epoch 24 of 200:\t\t40.84 seconds;\ttotal: 979.87;\tminutes left: 114.32\n",
            "Generator loss: 6.95225525, Discriminator loss: 0.06036, Unrolled Discriminator loss: 0.04645\n",
            "Epoch 25 of 200:\t\t40.61 seconds;\ttotal: 1020.48;\tminutes left: 113.82\n",
            "Generator loss: 7.36893511, Discriminator loss: 0.07866, Unrolled Discriminator loss: 0.05929\n",
            "Epoch 26 of 200:\t\t40.63 seconds;\ttotal: 1061.11;\tminutes left: 113.32\n",
            "Generator loss: 7.81910467, Discriminator loss: 0.10863, Unrolled Discriminator loss: 0.08264\n",
            "Epoch 27 of 200:\t\t40.80 seconds;\ttotal: 1101.91;\tminutes left: 112.81\n",
            "Generator loss: 7.29494476, Discriminator loss: 0.08441, Unrolled Discriminator loss: 0.06177\n",
            "Epoch 28 of 200:\t\t41.56 seconds;\ttotal: 1143.47;\tminutes left: 112.38\n",
            "Generator loss: 7.80325842, Discriminator loss: 0.08573, Unrolled Discriminator loss: 0.06805\n",
            "Epoch 29 of 200:\t\t42.72 seconds;\ttotal: 1186.19;\tminutes left: 112.03\n",
            "Generator loss: 7.59561396, Discriminator loss: 0.08084, Unrolled Discriminator loss: 0.05962\n",
            "Epoch 30 of 200:\t\t42.06 seconds;\ttotal: 1228.25;\tminutes left: 111.60\n",
            "Generator loss: 7.77239132, Discriminator loss: 0.08565, Unrolled Discriminator loss: 0.06141\n",
            "Epoch 31 of 200:\t\t40.66 seconds;\ttotal: 1268.91;\tminutes left: 111.03\n",
            "Generator loss: 9.46922493, Discriminator loss: 0.21955, Unrolled Discriminator loss: 0.18676\n",
            "Epoch 32 of 200:\t\t41.24 seconds;\ttotal: 1310.15;\tminutes left: 110.50\n",
            "Generator loss: 6.19099903, Discriminator loss: 0.15829, Unrolled Discriminator loss: 0.12522\n",
            "Epoch 33 of 200:\t\t42.18 seconds;\ttotal: 1352.33;\tminutes left: 110.04\n",
            "Generator loss: 6.26980734, Discriminator loss: 0.13392, Unrolled Discriminator loss: 0.10131\n",
            "Epoch 34 of 200:\t\t41.39 seconds;\ttotal: 1393.72;\tminutes left: 109.51\n",
            "Generator loss: 7.73616362, Discriminator loss: 0.16101, Unrolled Discriminator loss: 0.12635\n",
            "Epoch 35 of 200:\t\t41.64 seconds;\ttotal: 1435.35;\tminutes left: 108.98\n",
            "Generator loss: 6.40311813, Discriminator loss: 0.15940, Unrolled Discriminator loss: 0.12072\n",
            "Epoch 36 of 200:\t\t41.56 seconds;\ttotal: 1476.91;\tminutes left: 108.44\n",
            "Generator loss: 6.80335712, Discriminator loss: 0.12718, Unrolled Discriminator loss: 0.09986\n",
            "Epoch 37 of 200:\t\t42.80 seconds;\ttotal: 1519.71;\tminutes left: 107.98\n",
            "Generator loss: 5.82309341, Discriminator loss: 0.13835, Unrolled Discriminator loss: 0.10888\n",
            "Epoch 38 of 200:\t\t42.61 seconds;\ttotal: 1562.33;\tminutes left: 107.49\n",
            "Generator loss: 5.72285128, Discriminator loss: 0.12465, Unrolled Discriminator loss: 0.09673\n",
            "Epoch 39 of 200:\t\t43.61 seconds;\ttotal: 1605.93;\tminutes left: 107.06\n",
            "Generator loss: 6.33792162, Discriminator loss: 0.13054, Unrolled Discriminator loss: 0.09580\n",
            "Epoch 40 of 200:\t\t45.08 seconds;\ttotal: 1651.02;\tminutes left: 106.71\n",
            "Generator loss: 7.49904633, Discriminator loss: 0.13361, Unrolled Discriminator loss: 0.09721\n",
            "Epoch 41 of 200:\t\t41.78 seconds;\ttotal: 1692.80;\tminutes left: 106.14\n",
            "Generator loss: 7.06865501, Discriminator loss: 0.14083, Unrolled Discriminator loss: 0.10419\n",
            "Epoch 42 of 200:\t\t41.68 seconds;\ttotal: 1734.48;\tminutes left: 105.55\n",
            "Generator loss: 6.39973927, Discriminator loss: 0.09969, Unrolled Discriminator loss: 0.07624\n",
            "Epoch 43 of 200:\t\t42.65 seconds;\ttotal: 1777.13;\tminutes left: 105.01\n",
            "Generator loss: 8.60153103, Discriminator loss: 0.31935, Unrolled Discriminator loss: 0.26960\n",
            "Epoch 44 of 200:\t\t42.41 seconds;\ttotal: 1819.54;\tminutes left: 104.45\n",
            "Generator loss: 5.03143930, Discriminator loss: 0.17664, Unrolled Discriminator loss: 0.14026\n",
            "Epoch 45 of 200:\t\t42.36 seconds;\ttotal: 1861.90;\tminutes left: 103.89\n",
            "Generator loss: 5.61264801, Discriminator loss: 0.13802, Unrolled Discriminator loss: 0.10497\n",
            "Epoch 46 of 200:\t\t42.49 seconds;\ttotal: 1904.39;\tminutes left: 103.32\n",
            "Generator loss: 6.31577730, Discriminator loss: 0.15612, Unrolled Discriminator loss: 0.11765\n",
            "Epoch 47 of 200:\t\t43.07 seconds;\ttotal: 1947.46;\tminutes left: 102.78\n",
            "Generator loss: 7.02654362, Discriminator loss: 0.15539, Unrolled Discriminator loss: 0.11126\n",
            "Epoch 48 of 200:\t\t43.24 seconds;\ttotal: 1990.70;\tminutes left: 102.24\n",
            "Generator loss: 6.73333597, Discriminator loss: 0.14324, Unrolled Discriminator loss: 0.10394\n",
            "Epoch 49 of 200:\t\t44.10 seconds;\ttotal: 2034.80;\tminutes left: 101.74\n",
            "Generator loss: 7.06197262, Discriminator loss: 0.12361, Unrolled Discriminator loss: 0.09333\n",
            "Epoch 50 of 200:\t\t45.70 seconds;\ttotal: 2080.50;\tminutes left: 101.31\n",
            "Generator loss: 6.25283051, Discriminator loss: 0.11378, Unrolled Discriminator loss: 0.08890\n",
            "Epoch 51 of 200:\t\t43.91 seconds;\ttotal: 2124.41;\tminutes left: 100.77\n",
            "Generator loss: 6.22261906, Discriminator loss: 0.12208, Unrolled Discriminator loss: 0.09454\n",
            "Epoch 52 of 200:\t\t43.25 seconds;\ttotal: 2167.66;\tminutes left: 100.20\n",
            "Generator loss: 6.45123911, Discriminator loss: 0.15012, Unrolled Discriminator loss: 0.11827\n",
            "Epoch 53 of 200:\t\t44.66 seconds;\ttotal: 2212.32;\tminutes left: 99.69\n",
            "Generator loss: 6.44992399, Discriminator loss: 0.13855, Unrolled Discriminator loss: 0.09899\n",
            "Epoch 54 of 200:\t\t41.20 seconds;\ttotal: 2253.52;\tminutes left: 99.02\n",
            "Generator loss: 6.71139431, Discriminator loss: 0.14619, Unrolled Discriminator loss: 0.10317\n",
            "Epoch 55 of 200:\t\t41.93 seconds;\ttotal: 2295.45;\tminutes left: 98.38\n",
            "Generator loss: 7.58390284, Discriminator loss: 0.19678, Unrolled Discriminator loss: 0.13773\n",
            "Epoch 56 of 200:\t\t41.70 seconds;\ttotal: 2337.15;\tminutes left: 97.72\n",
            "Generator loss: 6.35600948, Discriminator loss: 0.13188, Unrolled Discriminator loss: 0.10241\n",
            "Epoch 57 of 200:\t\t41.39 seconds;\ttotal: 2378.54;\tminutes left: 97.06\n",
            "Generator loss: 5.68511534, Discriminator loss: 0.12074, Unrolled Discriminator loss: 0.09683\n",
            "Epoch 58 of 200:\t\t41.45 seconds;\ttotal: 2419.99;\tminutes left: 96.39\n",
            "Generator loss: 5.70782089, Discriminator loss: 0.14845, Unrolled Discriminator loss: 0.12103\n",
            "Epoch 59 of 200:\t\t41.24 seconds;\ttotal: 2461.23;\tminutes left: 95.71\n",
            "Generator loss: 5.40386438, Discriminator loss: 0.18337, Unrolled Discriminator loss: 0.14506\n",
            "Epoch 60 of 200:\t\t41.25 seconds;\ttotal: 2502.48;\tminutes left: 95.04\n",
            "Generator loss: 5.79036427, Discriminator loss: 0.16109, Unrolled Discriminator loss: 0.12068\n",
            "Epoch 61 of 200:\t\t41.33 seconds;\ttotal: 2543.81;\tminutes left: 94.37\n",
            "Generator loss: 5.71235704, Discriminator loss: 0.15719, Unrolled Discriminator loss: 0.11696\n",
            "Epoch 62 of 200:\t\t40.36 seconds;\ttotal: 2584.18;\tminutes left: 93.66\n",
            "Generator loss: 7.97254610, Discriminator loss: 0.32411, Unrolled Discriminator loss: 0.24911\n",
            "Epoch 63 of 200:\t\t41.00 seconds;\ttotal: 2625.18;\tminutes left: 92.98\n",
            "Generator loss: 4.85466003, Discriminator loss: 0.19772, Unrolled Discriminator loss: 0.16072\n",
            "Epoch 64 of 200:\t\t41.01 seconds;\ttotal: 2666.19;\tminutes left: 92.29\n",
            "Generator loss: 5.25525427, Discriminator loss: 0.17534, Unrolled Discriminator loss: 0.13924\n",
            "Epoch 65 of 200:\t\t42.58 seconds;\ttotal: 2708.77;\tminutes left: 91.66\n",
            "Generator loss: 5.74030256, Discriminator loss: 0.16068, Unrolled Discriminator loss: 0.11986\n",
            "Epoch 66 of 200:\t\t49.56 seconds;\ttotal: 2758.33;\tminutes left: 91.26\n",
            "Generator loss: 8.67195320, Discriminator loss: 0.31962, Unrolled Discriminator loss: 0.23979\n",
            "Epoch 67 of 200:\t\t42.43 seconds;\ttotal: 2800.76;\tminutes left: 90.61\n",
            "Generator loss: 5.39819241, Discriminator loss: 0.23430, Unrolled Discriminator loss: 0.17273\n",
            "Epoch 68 of 200:\t\t41.35 seconds;\ttotal: 2842.12;\tminutes left: 89.93\n",
            "Generator loss: 5.33175802, Discriminator loss: 0.12134, Unrolled Discriminator loss: 0.09499\n",
            "Epoch 69 of 200:\t\t45.55 seconds;\ttotal: 2887.67;\tminutes left: 89.38\n",
            "Generator loss: 5.50165653, Discriminator loss: 0.14818, Unrolled Discriminator loss: 0.11859\n",
            "Epoch 70 of 200:\t\t44.33 seconds;\ttotal: 2932.00;\tminutes left: 88.79\n",
            "Generator loss: 7.53595066, Discriminator loss: 0.46085, Unrolled Discriminator loss: 0.38099\n",
            "Epoch 71 of 200:\t\t42.84 seconds;\ttotal: 2974.84;\tminutes left: 88.14\n",
            "Generator loss: 4.85581350, Discriminator loss: 0.29109, Unrolled Discriminator loss: 0.22486\n",
            "Epoch 72 of 200:\t\t42.90 seconds;\ttotal: 3017.73;\tminutes left: 87.50\n",
            "Generator loss: 5.27269983, Discriminator loss: 0.24389, Unrolled Discriminator loss: 0.18705\n",
            "Epoch 73 of 200:\t\t44.28 seconds;\ttotal: 3062.01;\tminutes left: 86.89\n",
            "Generator loss: 6.11828232, Discriminator loss: 0.22772, Unrolled Discriminator loss: 0.17002\n",
            "Epoch 74 of 200:\t\t44.23 seconds;\ttotal: 3106.24;\tminutes left: 86.28\n",
            "Generator loss: 6.56013107, Discriminator loss: 0.26712, Unrolled Discriminator loss: 0.19970\n",
            "Epoch 75 of 200:\t\t43.76 seconds;\ttotal: 3150.00;\tminutes left: 85.66\n",
            "Generator loss: 6.27208376, Discriminator loss: 0.26437, Unrolled Discriminator loss: 0.19519\n",
            "Epoch 76 of 200:\t\t45.32 seconds;\ttotal: 3195.32;\tminutes left: 85.07\n",
            "Generator loss: 6.20225716, Discriminator loss: 0.19643, Unrolled Discriminator loss: 0.15414\n",
            "Epoch 77 of 200:\t\t45.13 seconds;\ttotal: 3240.45;\tminutes left: 84.47\n",
            "Generator loss: 5.75418282, Discriminator loss: 0.18949, Unrolled Discriminator loss: 0.14677\n",
            "Epoch 78 of 200:\t\t43.02 seconds;\ttotal: 3283.47;\tminutes left: 83.82\n",
            "Generator loss: 5.75275087, Discriminator loss: 0.20213, Unrolled Discriminator loss: 0.15455\n",
            "Epoch 79 of 200:\t\t44.20 seconds;\ttotal: 3327.66;\tminutes left: 83.19\n",
            "Generator loss: 6.29099512, Discriminator loss: 0.22227, Unrolled Discriminator loss: 0.16661\n",
            "Epoch 80 of 200:\t\t44.40 seconds;\ttotal: 3372.06;\tminutes left: 82.57\n",
            "Generator loss: 5.91206837, Discriminator loss: 0.23620, Unrolled Discriminator loss: 0.17644\n",
            "Epoch 81 of 200:\t\t46.25 seconds;\ttotal: 3418.32;\tminutes left: 81.98\n",
            "Generator loss: 5.56726313, Discriminator loss: 0.18533, Unrolled Discriminator loss: 0.14020\n",
            "Epoch 82 of 200:\t\t45.70 seconds;\ttotal: 3464.02;\tminutes left: 81.38\n",
            "Generator loss: 6.60444403, Discriminator loss: 0.19149, Unrolled Discriminator loss: 0.14216\n",
            "Epoch 83 of 200:\t\t42.65 seconds;\ttotal: 3506.67;\tminutes left: 80.71\n",
            "Generator loss: 6.06659555, Discriminator loss: 0.20997, Unrolled Discriminator loss: 0.15747\n",
            "Epoch 84 of 200:\t\t42.45 seconds;\ttotal: 3549.12;\tminutes left: 80.03\n",
            "Generator loss: 5.00267315, Discriminator loss: 0.17420, Unrolled Discriminator loss: 0.14039\n",
            "Epoch 85 of 200:\t\t42.63 seconds;\ttotal: 3591.75;\tminutes left: 79.35\n",
            "Generator loss: 5.20127058, Discriminator loss: 0.18601, Unrolled Discriminator loss: 0.14802\n",
            "Epoch 86 of 200:\t\t43.52 seconds;\ttotal: 3635.27;\tminutes left: 78.69\n",
            "Generator loss: 5.53886938, Discriminator loss: 0.19239, Unrolled Discriminator loss: 0.15426\n",
            "Epoch 87 of 200:\t\t44.67 seconds;\ttotal: 3679.94;\tminutes left: 78.06\n",
            "Generator loss: 5.34044790, Discriminator loss: 0.20077, Unrolled Discriminator loss: 0.15581\n",
            "Epoch 88 of 200:\t\t42.28 seconds;\ttotal: 3722.22;\tminutes left: 77.37\n",
            "Generator loss: 5.82607174, Discriminator loss: 0.26452, Unrolled Discriminator loss: 0.20070\n",
            "Epoch 89 of 200:\t\t42.67 seconds;\ttotal: 3764.89;\tminutes left: 76.69\n",
            "Generator loss: 5.56288195, Discriminator loss: 0.24655, Unrolled Discriminator loss: 0.18820\n",
            "Epoch 90 of 200:\t\t42.74 seconds;\ttotal: 3807.63;\tminutes left: 76.01\n",
            "Generator loss: 5.71073246, Discriminator loss: 0.22608, Unrolled Discriminator loss: 0.16896\n",
            "Epoch 91 of 200:\t\t42.44 seconds;\ttotal: 3850.07;\tminutes left: 75.33\n",
            "Generator loss: 5.69915199, Discriminator loss: 0.21834, Unrolled Discriminator loss: 0.16806\n",
            "Epoch 92 of 200:\t\t44.26 seconds;\ttotal: 3894.33;\tminutes left: 74.68\n",
            "Generator loss: 5.68302679, Discriminator loss: 0.21265, Unrolled Discriminator loss: 0.16161\n",
            "Epoch 93 of 200:\t\t42.80 seconds;\ttotal: 3937.14;\tminutes left: 74.00\n",
            "Generator loss: 5.88959074, Discriminator loss: 0.25502, Unrolled Discriminator loss: 0.19494\n",
            "Epoch 94 of 200:\t\t45.69 seconds;\ttotal: 3982.83;\tminutes left: 73.37\n",
            "Generator loss: 6.14315701, Discriminator loss: 0.26761, Unrolled Discriminator loss: 0.20330\n",
            "Epoch 95 of 200:\t\t42.65 seconds;\ttotal: 4025.48;\tminutes left: 72.68\n",
            "Generator loss: 4.91361952, Discriminator loss: 0.22396, Unrolled Discriminator loss: 0.17644\n",
            "Epoch 96 of 200:\t\t43.84 seconds;\ttotal: 4069.32;\tminutes left: 72.02\n",
            "Generator loss: 6.00574160, Discriminator loss: 0.22643, Unrolled Discriminator loss: 0.17137\n",
            "Epoch 97 of 200:\t\t42.84 seconds;\ttotal: 4112.16;\tminutes left: 71.33\n",
            "Generator loss: 6.74154329, Discriminator loss: 0.29567, Unrolled Discriminator loss: 0.23195\n",
            "Epoch 98 of 200:\t\t43.12 seconds;\ttotal: 4155.28;\tminutes left: 70.65\n",
            "Generator loss: 5.27806997, Discriminator loss: 0.21350, Unrolled Discriminator loss: 0.16907\n",
            "Epoch 99 of 200:\t\t41.03 seconds;\ttotal: 4196.31;\tminutes left: 69.94\n",
            "Generator loss: 5.82664108, Discriminator loss: 0.26927, Unrolled Discriminator loss: 0.20672\n",
            "Epoch 100 of 200:\t\t41.14 seconds;\ttotal: 4237.45;\tminutes left: 69.23\n",
            "Generator loss: 5.56323481, Discriminator loss: 0.26621, Unrolled Discriminator loss: 0.20286\n",
            "Epoch 101 of 200:\t\t41.48 seconds;\ttotal: 4278.93;\tminutes left: 68.52\n",
            "Generator loss: 5.25733185, Discriminator loss: 0.25816, Unrolled Discriminator loss: 0.20228\n",
            "Epoch 102 of 200:\t\t41.74 seconds;\ttotal: 4320.67;\tminutes left: 67.82\n",
            "Generator loss: 5.77905178, Discriminator loss: 0.23054, Unrolled Discriminator loss: 0.17845\n",
            "Epoch 103 of 200:\t\t41.95 seconds;\ttotal: 4362.63;\tminutes left: 67.12\n",
            "Generator loss: 6.66496563, Discriminator loss: 0.28705, Unrolled Discriminator loss: 0.21489\n",
            "Epoch 104 of 200:\t\t41.60 seconds;\ttotal: 4404.22;\tminutes left: 66.41\n",
            "Generator loss: 4.66750860, Discriminator loss: 0.22629, Unrolled Discriminator loss: 0.18240\n",
            "Epoch 105 of 200:\t\t40.82 seconds;\ttotal: 4445.05;\tminutes left: 65.70\n",
            "Generator loss: 5.93688297, Discriminator loss: 0.26208, Unrolled Discriminator loss: 0.20237\n",
            "Epoch 106 of 200:\t\t41.42 seconds;\ttotal: 4486.47;\tminutes left: 64.99\n",
            "Generator loss: 6.22185135, Discriminator loss: 0.27582, Unrolled Discriminator loss: 0.20575\n",
            "Epoch 107 of 200:\t\t40.45 seconds;\ttotal: 4526.91;\tminutes left: 64.27\n",
            "Generator loss: 5.68820238, Discriminator loss: 0.34589, Unrolled Discriminator loss: 0.26498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NV1Vtj8JYOla"
      },
      "source": [
        "print('DONE TRAINING')\n",
        "torch.save(generator.state_dict(), path + 'generator.pth')\n",
        "path"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DONE TRAINING\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-92aa732d7a94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DONE TRAINING'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'generator.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "II3WYevue4FW"
      },
      "source": [
        "imgs = [np.array(to_pil_image(img)) for img in images]\n",
        "imageio.mimsave(path + 'generator_images.gif', imgs)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "vQTiNztJfVpt",
        "outputId": "78767a7f-79ac-4366-f16f-eae67e5a96a8"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(losses_g, label='Generator loss')\n",
        "plt.plot(losses_d, label='Discriminator Loss')\n",
        "plt.legend()\n",
        "plt.savefig(path + 'loss.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZE4GO9YDfash"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}