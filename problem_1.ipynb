{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python382jvsc74a57bd0a94883f8812057f41bf7c0f7649a41127778eaf25b6b91e0966940eb42cb8f65",
      "display_name": "Python 3.8.2 64-bit ('HW3': venv)"
    },
    "metadata": {
      "interpreter": {
        "hash": "a94883f8812057f41bf7c0f7649a41127778eaf25b6b91e0966940eb42cb8f65"
      }
    },
    "colab": {
      "name": "problem_1.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb3v-7vPca6E"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import re\n",
        "import time\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.nn import Module, GRU, Embedding, Linear, Sigmoid, CrossEntropyLoss"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2vJl0i5ca6V"
      },
      "source": [
        "# Part 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHjwy_3zcpui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fe5d0e8-e32c-40c0-87fb-fcca9978f63a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UrqY84fca6V"
      },
      "source": [
        "\"data/sentiment_analysis/train_pos_merged.txt\"\n",
        "# function clearing HTML tags from text\n",
        "def cleanhtml(raw_html):\n",
        "    cleanr = re.compile('<.*?>')\n",
        "    cleantext = re.sub(cleanr, '', raw_html)\n",
        "    return cleantext\n",
        "\n",
        "# preprocessing\n",
        "def clean_text(path):\n",
        "    reviews = []\n",
        "    all_words = []\n",
        "    with open(path) as pos:\n",
        "        lines = pos.readlines()\n",
        "        for line in lines:\n",
        "            #clear html tags\n",
        "            line = cleanhtml(line)\n",
        "            # lower case and punctuation\n",
        "            line = re.sub(r'[^a-zA-Z]', ' ', line.lower())\n",
        "            # split to list of words\n",
        "            words = line.split()\n",
        "            # add list to reviews\n",
        "            reviews.append(words)\n",
        "            # extend words with new review\n",
        "            all_words.extend(words)\n",
        "\n",
        "    return reviews, all_words\n",
        "\n",
        "def create_vocab(words):\n",
        "    # create vocabulary with indexes\n",
        "    vocab = {}\n",
        "    id = 1\n",
        "    for word in words:\n",
        "        if word not in vocab.keys():\n",
        "            vocab[word] = id\n",
        "            id += 1\n",
        "    return vocab\n",
        "\n",
        "\n",
        "def vectorize_data(reviews, y, vocab, LENGTH=400):\n",
        "    y = np.array([y for _ in range(len(reviews))])\n",
        "    indexed_reviews = np.zeros((len(reviews), LENGTH), dtype = np.int64)\n",
        "    for i, review in enumerate(reviews):\n",
        "        indexed_review = []\n",
        "        for word in review:\n",
        "            indexed_review.append(vocab[word])\n",
        "        indexed_reviews[i, max(LENGTH-len(review),0):] = indexed_review[:400]\n",
        "    return indexed_reviews, y\n",
        "\n",
        "def preprocessing(path1, path2, y1, y2, vocab, LENGTH=400):\n",
        "    reviews1, words1 = clean_text(path1)\n",
        "    reviews2, words2 = clean_text(path2)\n",
        "    # words1.extend(words2)\n",
        "    # print(words1)\n",
        "\n",
        "    del words1, words2\n",
        "\n",
        "    # vocab = create_vocab(words1)\n",
        "\n",
        "    x1, y1 = vectorize_data(reviews1, y1, vocab, LENGTH)\n",
        "    x2, y2 = vectorize_data(reviews2, y2, vocab, LENGTH)\n",
        "\n",
        "    x = np.concatenate((x1, x2))\n",
        "    y = np.concatenate((y1, y2))\n",
        "\n",
        "    return x, y #, vocab\n",
        "\n",
        "\n",
        "\n",
        "        "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "lRDL7nvqca6W"
      },
      "source": [
        "reviews, words = clean_text(\"all_merged.txt\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66iWArgxet3P"
      },
      "source": [
        "vocab = create_vocab(words)\n",
        "# vocab"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neX_8Zayfkhv"
      },
      "source": [
        "train_x, train_y = preprocessing(\"train_pos_merged.txt\", \"train_neg_merged.txt\", 0, 1, vocab)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geRNeiBuo6UP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb846d9a-322e-4963-86ff-a21cc75abb4c"
      },
      "source": [
        "input = torch.from_numpy(train_x[0])\n",
        "embedding = Embedding(len(vocab), 3, padding_idx=0)\n",
        "embedding(input)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000],\n",
              "        ...,\n",
              "        [-0.0097, -0.3403,  0.6032],\n",
              "        [-0.3085, -0.1683,  0.2404],\n",
              "        [ 0.5380, -0.8329,  1.7965]], grad_fn=<EmbeddingBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWOwMMSXca6Y"
      },
      "source": [
        "batch_size = 100\n",
        "train_data =  TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzEaZ1Ewca6Z"
      },
      "source": [
        "# Part 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_x9lfzQrca6Z"
      },
      "source": [
        "class GRU_model(Module):\n",
        "\n",
        "    def __init__(self, vocab_size, input_dim, hidden_dim, n_layers=1, LENGTH=400):\n",
        "        \n",
        "        super(GRU_model, self).__init__()\n",
        "        \n",
        "        self.input_dim = input_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.embedding = Embedding(vocab_size, input_dim, padding_idx=0)\n",
        "        self.gru = GRU(input_dim, hidden_dim, n_layers, batch_first=True)\n",
        "        self.linear = Linear(hidden_dim, 2)\n",
        "        self.sigmoid = Sigmoid()\n",
        "\n",
        "    def forward(self, x, h):\n",
        "        x = self.embedding(x)\n",
        "        x, h = self.gru(x, h)\n",
        "        # print(f\"shape of x: {x.shape}; shape of h: {h.shape}; shape of x[:,-1]: {x[:,-1].shape}\")\n",
        "        x = self.linear(x[:,-1])\n",
        "        # print(f\"shape of x: {x.shape}\")\n",
        "        x = self.sigmoid(x)\n",
        "        return x, h\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        weight = next(self.parameters()).data\n",
        "        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
        "        return hidden\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDvLKFg09VpN",
        "outputId": "03711bea-d683-43a6-87c4-19431b582e45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "gru_model.init_hidden()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-29deca7aa6f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgru_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-cb6d81c48ab2>\u001b[0m in \u001b[0;36minit_hidden\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: new(): argument 'size' must be tuple of ints, but found element of type numpy.ndarray at pos 2"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZOcAlKvca6Z"
      },
      "source": [
        "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1GQiq7h3XGZ",
        "outputId": "20c26014-4d7a-49a3-8542-9c9b116674a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "is_cuda"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm_fQL4Gca6a"
      },
      "source": [
        "def train(train_loader, vocab_size, learn_rate, input_dim=10, hidden_dim=16, EPOCHS=5):\n",
        "    \n",
        "    # Setting common hyperparameters\n",
        "    # input_dim = next(iter(train_loader))[0].shape[1]\n",
        "    # print(next(iter(train_loader))[0].shape[1])\n",
        "    output_dim = 1\n",
        "    n_layers = 1\n",
        "    # Instantiating the model\n",
        "    model = GRU_model(vocab_size, input_dim, hidden_dim, output_dim, n_layers)\n",
        "    model.to(device)\n",
        "    \n",
        "    # Defining loss function and optimizer\n",
        "    criterion = CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
        "    \n",
        "    model.train()\n",
        "    print(\"Starting Training\")\n",
        "    epoch_times = []\n",
        "    # Start training loop\n",
        "    for epoch in range(1,EPOCHS+1):\n",
        "        start_time = time.time()\n",
        "        h = model.init_hidden(batch_size)\n",
        "        avg_loss = 0.\n",
        "        counter = 0\n",
        "        for x, label in train_loader:\n",
        "            counter += 1\n",
        "            h = h.data\n",
        "            model.zero_grad()\n",
        "            \n",
        "            out, h = model(x.to(device), h)\n",
        "            # print(f\"shape of out.squeeze(): {out.squeeze().shape}; shape of label: {label.shape}\")\n",
        "            loss = criterion(out.squeeze(), label.to(device))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            avg_loss += loss.item()\n",
        "            if counter%100 == 0:\n",
        "                print(\"Epoch {}......Step: {}/{}....... Average Loss for Epoch: {}\".format(epoch, counter, len(train_loader), avg_loss/counter))\n",
        "        current_time = time.time()\n",
        "        print(\"Epoch {}/{} Done, Total Loss: {}\".format(epoch, EPOCHS, avg_loss/len(train_loader)))\n",
        "        print(\"Total Time Elapsed: {} seconds\".format(str(current_time-start_time)))\n",
        "        epoch_times.append(current_time-start_time)\n",
        "    print(\"Total Training Time: {} seconds\".format(str(sum(epoch_times))))\n",
        "    return model\n",
        "\n",
        "\n",
        "def evaluate(model, test_loader): #, label_scalers):\n",
        "    model.eval()\n",
        "    outputs = []\n",
        "    results = []\n",
        "    start_time = time.time()\n",
        "    model.eval()\n",
        "    err = 0\n",
        "    for x, label in test_loader:\n",
        "        h = model.init_hidden(test_loader.batch_size).data\n",
        "        input = x.to(device)\n",
        "        output, h_out = gru_model(input, h)\n",
        "        result = torch.argmax(output, dim=1)\n",
        "        results.append(result)\n",
        "        err += torch.abs(result.to(device) - label.to(device)).sum()\n",
        "    accuracy = 1 - err/len(test_loader)\n",
        "    return accuracy, outputs, results\n",
        "\n",
        "\n",
        "# def evaluate(model, test_x, test_y): #, label_scalers):\n",
        "#     model.eval()\n",
        "#     outputs = []\n",
        "#     results = []\n",
        "#     start_time = time.time()\n",
        "#     model.eval()\n",
        "#     err = 0\n",
        "#     for i in range(len(test_x)):\n",
        "#         input = torch.from_numpy(test_x[i]).view(1,400).to(device)\n",
        "#         h = gru_model.init_hidden(1)\n",
        "#         output, h_out = gru_model(input, h)\n",
        "#         result = torch.argmax(output)\n",
        "#         results.append(result)\n",
        "#         err += torch.abs(result - test_y[i])\n",
        "#     accuracy = 1 - err/len(test_x)\n",
        "#     return accuracy, outputs, results"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pyld89ckca6b"
      },
      "source": [
        "gru_model = train(\n",
        "    train_loader, \n",
        "    vocab_size = len(vocab), \n",
        "    learn_rate=0.0005, \n",
        "    hidden_dim=32, \n",
        "    EPOCHS=300\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hu30OGJlca6b",
        "outputId": "400cddfe-5e86-4ef6-8c4a-6361d9074ede",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gru_model.eval()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GRU_model(\n",
              "  (embedding): Embedding(39237, 10, padding_idx=0)\n",
              "  (gru): GRU(10, 32, batch_first=True)\n",
              "  (linear): Linear(in_features=32, out_features=2, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEjXCRTp6U3W"
      },
      "source": [
        "test_x, test_y = preprocessing(\"test_pos_merged.txt\", \"test_neg_merged.txt\", 0, 1, vocab)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC0Zdgdj7Lz5"
      },
      "source": [
        "# batch_size = 100\n",
        "test_data =  TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
        "test_loader = DataLoader(test_data) #, shuffle=True, batch_size=batch_size)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIJ2sIbz7hGH"
      },
      "source": [
        "accuracy, outputs, results = evaluate(gru_model, test_loader)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O08JCDG7Ct4p",
        "outputId": "a6982f43-7a06-4e90-c908-45e1b49fa500",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "accuracy"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6817, device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    }
  ]
}